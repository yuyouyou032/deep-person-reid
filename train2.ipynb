{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a5b8ed-63dd-4df6-a59e-1fe7c0f388d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchreid\n",
    "from torchreid.data.datasets.image.til2023_cv_dataset_2 import Til2023CvDataset2\n",
    "torchreid.data.register_image_dataset('til2023_cv_dataset_2', Til2023CvDataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0993a1e9-c9fb-4374-8439-f4778b9e3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "TRAIN:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00120_4145.png', 120, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00088_3517.png', 88, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00070_2828.png', 70, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00171_0489.png', 171, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00006_0255.png', 6, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00008_0323.png', 8, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00147_0402.png', 147, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00082_3304.png', 82, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00088_5131.png', 88, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00039_1596.png', 39, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00006_0554.png', 206, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0478.png', 205, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0764.png', 202, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00004_0310.png', 204, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0720.png', 200, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0317.png', 209, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0065.png', 207, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00003_0288.png', 203, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00003_0353.png', 203, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0240.png', 207, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0382.png', 207, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00004_0359.png', 204, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0459.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00001_0081.png', 201, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0221.png', 202, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00001_0663.png', 201, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00006_0485.png', 206, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0106.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0433.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0004.png', 200, 2)]\n",
      "=> Loaded Til2023CvDataset2\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   200 |    12316 |         1\n",
      "  query    |    10 |       50 |         1\n",
      "  gallery  |    10 |     1649 |         1\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "TRAIN:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00071_2857.png', 71, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00034_5355.png', 34, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00046_1858.png', 46, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00143_5094.png', 143, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00157_4849.png', 157, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00059_0630.png', 59, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00016_3351.png', 16, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00163_5417.png', 163, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00057_2280.png', 57, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00162_4960.png', 162, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0077.png', 202, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0231.png', 200, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0225.png', 205, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0731.png', 202, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0581.png', 207, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0412.png', 205, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0014.png', 200, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00001_0110.png', 201, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0755.png', 209, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00004_0061.png', 204, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00003_0304.png', 203, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0005.png', 200, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00003_0652.png', 203, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0004.png', 200, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00006_0749.png', 206, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00003_0308.png', 203, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00006_0499.png', 206, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0244.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0237.png', 202, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0765.png', 209, 2)]\n",
      "=> Loaded Til2023CvDataset2\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   200 |    12316 |         1\n",
      "  query    |    10 |       50 |         1\n",
      "  gallery  |    10 |     1649 |         1\n",
      "  ----------------------------------------\n",
      "TRAIN:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00028_1143.png', 28, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00195_5160.png', 195, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00104_1903.png', 104, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00100_5267.png', 100, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00161_4935.png', 161, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00017_1001.png', 17, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00030_1684.png', 30, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00003_0143.png', 3, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00029_4768.png', 29, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Train1/00184_5362.png', 184, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0638.png', 207, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0794.png', 209, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0435.png', 205, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00000_0151.png', 200, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0725.png', 209, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0420.png', 205, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00004_0328.png', 204, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0549.png', 202, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0119.png', 207, 0), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00008_0675.png', 208, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0763.png', 209, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00009_0161.png', 209, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0191.png', 202, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00002_0187.png', 202, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00007_0314.png', 207, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0092.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00005_0276.png', 205, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00008_0712.png', 208, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00001_0080.png', 201, 2), ('/notebooks/deep-person-reid/reid-data/til2023_cv_dataset/Validation1/00006_0420.png', 206, 2)]\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['til2023_cv_dataset_2']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 200\n",
      "  # source images   : 12316\n",
      "  # source cameras  : 1\n",
      "  target            : ['til2023_cv_dataset_2']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root='reid-data',\n",
    "    sources='til2023_cv_dataset_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59963de5-ce97-4621-8c92-04f5573b6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"resnet50\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e92403-0352-4c44-9dcb-8ad442ae22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f36238-0b77-47b6-b0e6-9954925e9ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Start training\n",
      "epoch: [1/4][50/384]\ttime 0.233 (0.279)\tdata 0.000 (0.010)\teta 0:06:55\tloss 3.7541 (4.7862)\tacc 28.1250 (12.3125)\tlr 0.000300\n",
      "epoch: [1/4][100/384]\ttime 0.237 (0.257)\tdata 0.001 (0.005)\teta 0:06:09\tloss 2.6578 (3.9337)\tacc 40.6250 (25.1250)\tlr 0.000300\n",
      "epoch: [1/4][150/384]\ttime 0.236 (0.250)\tdata 0.001 (0.004)\teta 0:05:46\tloss 2.0644 (3.4007)\tacc 65.6250 (36.1042)\tlr 0.000300\n",
      "epoch: [1/4][200/384]\ttime 0.239 (0.247)\tdata 0.001 (0.003)\teta 0:05:29\tloss 1.9149 (3.0342)\tacc 65.6250 (44.2500)\tlr 0.000300\n",
      "epoch: [1/4][250/384]\ttime 0.237 (0.245)\tdata 0.001 (0.002)\teta 0:05:14\tloss 1.5858 (2.7761)\tacc 87.5000 (50.7000)\tlr 0.000300\n",
      "epoch: [1/4][300/384]\ttime 0.238 (0.244)\tdata 0.000 (0.002)\teta 0:05:01\tloss 1.4053 (2.5804)\tacc 90.6250 (55.7396)\tlr 0.000300\n",
      "epoch: [1/4][350/384]\ttime 0.237 (0.243)\tdata 0.001 (0.002)\teta 0:04:48\tloss 1.3341 (2.4300)\tacc 90.6250 (59.6964)\tlr 0.000300\n",
      "##### Evaluating til2023_cv_dataset_2 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 50-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 1649-by-2048 matrix\n",
      "Speed: 0.0193 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 83.9%\n",
      "CMC curve\n",
      "Rank-1  : 100.0%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "Checkpoint saved to \"log/til_resnet50/model/model.pth.tar-1\"\n",
      "epoch: [2/4][50/384]\ttime 0.239 (0.251)\tdata 0.001 (0.012)\teta 0:04:36\tloss 1.5225 (1.3930)\tacc 81.2500 (87.6875)\tlr 0.000300\n",
      "epoch: [2/4][100/384]\ttime 0.242 (0.245)\tdata 0.001 (0.006)\teta 0:04:17\tloss 1.2947 (1.3731)\tacc 90.6250 (88.9062)\tlr 0.000300\n",
      "epoch: [2/4][150/384]\ttime 0.239 (0.243)\tdata 0.000 (0.005)\teta 0:04:03\tloss 1.3181 (1.3573)\tacc 96.8750 (89.6458)\tlr 0.000300\n",
      "epoch: [2/4][200/384]\ttime 0.238 (0.242)\tdata 0.001 (0.004)\teta 0:03:50\tloss 1.4365 (1.3522)\tacc 84.3750 (89.7969)\tlr 0.000300\n",
      "epoch: [2/4][250/384]\ttime 0.239 (0.241)\tdata 0.001 (0.003)\teta 0:03:37\tloss 1.3779 (1.3538)\tacc 90.6250 (89.6250)\tlr 0.000300\n",
      "epoch: [2/4][300/384]\ttime 0.239 (0.241)\tdata 0.000 (0.003)\teta 0:03:25\tloss 1.4265 (1.3610)\tacc 84.3750 (89.4167)\tlr 0.000300\n",
      "epoch: [2/4][350/384]\ttime 0.240 (0.241)\tdata 0.001 (0.002)\teta 0:03:13\tloss 1.4614 (1.3584)\tacc 87.5000 (89.3571)\tlr 0.000300\n",
      "##### Evaluating til2023_cv_dataset_2 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 50-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 1649-by-2048 matrix\n",
      "Speed: 0.0144 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 87.5%\n",
      "CMC curve\n",
      "Rank-1  : 100.0%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "Checkpoint saved to \"log/til_resnet50/model/model.pth.tar-2\"\n",
      "epoch: [3/4][50/384]\ttime 0.241 (0.248)\tdata 0.001 (0.009)\teta 0:02:58\tloss 1.1063 (1.2167)\tacc 96.8750 (94.1250)\tlr 0.000300\n",
      "epoch: [3/4][100/384]\ttime 0.240 (0.244)\tdata 0.001 (0.005)\teta 0:02:43\tloss 1.1907 (1.2059)\tacc 90.6250 (94.2188)\tlr 0.000300\n",
      "epoch: [3/4][150/384]\ttime 0.241 (0.243)\tdata 0.001 (0.004)\teta 0:02:30\tloss 1.2803 (1.2159)\tacc 90.6250 (93.7917)\tlr 0.000300\n",
      "epoch: [3/4][200/384]\ttime 0.237 (0.242)\tdata 0.000 (0.003)\teta 0:02:17\tloss 1.1234 (1.2286)\tacc 96.8750 (93.3438)\tlr 0.000300\n",
      "epoch: [3/4][250/384]\ttime 0.241 (0.241)\tdata 0.000 (0.002)\teta 0:02:05\tloss 1.1569 (1.2312)\tacc 96.8750 (93.1875)\tlr 0.000300\n",
      "epoch: [3/4][300/384]\ttime 0.241 (0.241)\tdata 0.000 (0.002)\teta 0:01:52\tloss 1.1728 (1.2312)\tacc 90.6250 (93.2083)\tlr 0.000300\n",
      "epoch: [3/4][350/384]\ttime 0.239 (0.241)\tdata 0.000 (0.002)\teta 0:01:40\tloss 1.3024 (1.2359)\tacc 93.7500 (93.0536)\tlr 0.000300\n",
      "##### Evaluating til2023_cv_dataset_2 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 50-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 1649-by-2048 matrix\n",
      "Speed: 0.0153 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 87.7%\n",
      "CMC curve\n",
      "Rank-1  : 100.0%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "Checkpoint saved to \"log/til_resnet50/model/model.pth.tar-3\"\n",
      "epoch: [4/4][50/384]\ttime 0.240 (0.248)\tdata 0.001 (0.009)\teta 0:01:22\tloss 1.0908 (1.1696)\tacc 100.0000 (95.6250)\tlr 0.000300\n",
      "epoch: [4/4][100/384]\ttime 0.239 (0.244)\tdata 0.000 (0.005)\teta 0:01:09\tloss 1.2030 (1.1711)\tacc 90.6250 (95.0625)\tlr 0.000300\n",
      "epoch: [4/4][150/384]\ttime 0.240 (0.242)\tdata 0.000 (0.003)\teta 0:00:56\tloss 1.1550 (1.1777)\tacc 96.8750 (94.7500)\tlr 0.000300\n",
      "epoch: [4/4][200/384]\ttime 0.239 (0.242)\tdata 0.001 (0.003)\teta 0:00:44\tloss 1.1618 (1.1783)\tacc 93.7500 (94.8125)\tlr 0.000300\n",
      "epoch: [4/4][250/384]\ttime 0.239 (0.241)\tdata 0.001 (0.002)\teta 0:00:32\tloss 1.2408 (1.1825)\tacc 96.8750 (94.6750)\tlr 0.000300\n",
      "epoch: [4/4][300/384]\ttime 0.238 (0.241)\tdata 0.001 (0.002)\teta 0:00:20\tloss 1.2053 (1.1832)\tacc 93.7500 (94.5938)\tlr 0.000300\n",
      "epoch: [4/4][350/384]\ttime 0.239 (0.241)\tdata 0.001 (0.002)\teta 0:00:08\tloss 1.2054 (1.1828)\tacc 96.8750 (94.5804)\tlr 0.000300\n",
      "=> Final test\n",
      "##### Evaluating til2023_cv_dataset_2 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 50-by-2048 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 1649-by-2048 matrix\n",
      "Speed: 0.0128 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 89.0%\n",
      "CMC curve\n",
      "Rank-1  : 100.0%\n",
      "Rank-5  : 100.0%\n",
      "Rank-10 : 100.0%\n",
      "Rank-20 : 100.0%\n",
      "Checkpoint saved to \"log/til_resnet50/model/model.pth.tar-4\"\n",
      "Elapsed 0:06:34\n"
     ]
    }
   ],
   "source": [
    "engine.run(\n",
    "    save_dir=\"log/til_resnet50\",\n",
    "    max_epoch=4,\n",
    "    eval_freq=1,\n",
    "    print_freq=50,\n",
    "    test_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7f17a-7e12-4e5a-b09a-8f4f7d824ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
