{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24df80cf-82f4-4a6d-aac9-001fd5db80f1",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e191ea6a-3336-498e-a174-688cf2d6e95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/deep-person-reid/torchreid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchreid\n",
    "from torchreid.data.datasets.image.robo import Robo\n",
    "torchreid.data.register_image_dataset('robo', Robo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2f01ab-3668-49ab-a53d-7b358132b805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "TRAIN:::  [('', 0, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/sus/suspect.png', 0, 0), ('/notebooks/deep-person-reid/reid-data/sus/hostage.png', 0, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/test/0.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/2.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/1.png', 0, 2)]\n",
      "=> Loaded Robo\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     1 |        1 |         1\n",
      "  query    |     1 |        2 |         1\n",
      "  gallery  |     1 |        3 |         1\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "TRAIN:::  [('', 0, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/sus/suspect.png', 0, 0), ('/notebooks/deep-person-reid/reid-data/sus/hostage.png', 0, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/test/2.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/0.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/1.png', 0, 2)]\n",
      "=> Loaded Robo\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |     1 |        1 |         1\n",
      "  query    |     1 |        2 |         1\n",
      "  gallery  |     1 |        3 |         1\n",
      "  ----------------------------------------\n",
      "TRAIN:::  [('', 0, 0)]\n",
      "QUERY:::  [('/notebooks/deep-person-reid/reid-data/sus/suspect.png', 0, 0), ('/notebooks/deep-person-reid/reid-data/sus/hostage.png', 0, 0)]\n",
      "GALLERY:::  [('/notebooks/deep-person-reid/reid-data/test/2.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/1.png', 0, 2), ('/notebooks/deep-person-reid/reid-data/test/0.png', 0, 2)]\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['robo']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 1\n",
      "  # source images   : 1\n",
      "  # source cameras  : 1\n",
      "  target            : ['robo']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root='reid-data',\n",
    "    sources='robo',\n",
    "    transforms = \"\",\n",
    "    use_gpu = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1241297-60d2-40f9-88cf-eaeceafe044f",
   "metadata": {},
   "source": [
    "# Assemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552bc2d-5ba4-4ace-9a04-b41b08fe7f3c",
   "metadata": {},
   "source": [
    "## model 1 - resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0d922-8d4d-4478-b715-581910c2a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"resnet50\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e5510-0626-4900-a1a7-5dc404b56eca",
   "metadata": {},
   "source": [
    "## mode 2 - resnet50mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171bbff-7f23-4c98-8f33-054344c7f042",
   "metadata": {},
   "source": [
    "## model 4 - osnet_ain_x0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e50363-a227-4ede-902c-51b1dd46cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_ain_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"triplet\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0015,\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27d29b-2f5f-4695-81e2-83ed96e9bef7",
   "metadata": {},
   "source": [
    "## model 5 - osnet_ain_x0_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f270d-065f-4c81-82ad-3c11321dda69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_ain_x0_25\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14a551-c00a-4808-a50a-2e9b3280c3d1",
   "metadata": {},
   "source": [
    "## model - osnet ibn x1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592ce806-ab70-463c-a4f7-25992167c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_ibn_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"triplet\",\n",
    "    pretrained=False # I DISABLED DOWNLOAD WEIGHTS!!!\n",
    ")\n",
    "\n",
    "# model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71cad71-08ed-402c-96df-c90a147ec8b5",
   "metadata": {},
   "source": [
    "# Assemble engine, load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d273fd-efaa-4369-bbee-9dddc72224a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.ImageTripletEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True,\n",
    "    use_gpu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c658bd2-29ab-4e6f-bdd5-5c004699cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded pretrained weights from \"/notebooks/deep-person-reid/log/til_osnet_ibn_x1_0_with_pretrained/model/model.pth.tar-10-95.7-460\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "from torchreid.utils import load_pretrained_weights\n",
    "weight_path = '/notebooks/deep-person-reid/log/til_osnet_ibn_x1_0_with_pretrained/model/model.pth.tar-10-95.7-460'\n",
    "load_pretrained_weights(model, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ee5c2-a5b9-4b37-a812-c65cabc4bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_path = '/notebooks/deep-person-reid/log/til_osnet_ibn_x1_0_with_pretrained/model/model.pth.tar-10-95.7-460'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8e8c0-a588-4c05-9fe0-6a1562da744e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_pretrained_weights(model, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd5bd75-2672-4c9f-896a-94e1cf442db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating robo (source) #####\n",
      "Extracting features from query set ...\n",
      "HELLO HERE ARE UR PIDS AND CAMIDS: \n",
      "[0 0] [0 0]\n",
      "Done, obtained 2-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "HELLO HERE ARE UR PIDS AND CAMIDS: \n",
      "[0 0 0] [2 2 2]\n",
      "Done, obtained 3-by-512 matrix\n",
      "Speed: 1.8293 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "YOUR DISTMAT!!!:  (2, 3)\n",
      "[544.4458  611.84644 536.5933 ]\n",
      "[628.04236 354.37045 730.9147 ]\n",
      "Computing CMC and mAP ...\n",
      "Note: number of gallery samples is quite small, got 3\n"
     ]
    }
   ],
   "source": [
    "_,distmat, queries_and_galley = engine.run(\n",
    "    save_dir=\"log/til_resnet50\",\n",
    "    max_epoch=4,\n",
    "    eval_freq=1,\n",
    "    print_freq=50,\n",
    "    test_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361a84a-3c6d-44b2-ba03-935b9069d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78280ed-7c73-432a-b5aa-b6380a4f8c02",
   "metadata": {},
   "source": [
    "# post process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b224ebf-89c1-402d-93d7-4539e4cf75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d84f88-f652-4da6-8d6c-10191f21c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_matches(d, q, index):\n",
    "    query = q[0][index][0]\n",
    "    distmat = d[index]\n",
    "    gallery = q[1]\n",
    "    \n",
    "    temp = zip(distmat, gallery)\n",
    "    print(\"#SUS \", query)\n",
    "    im=Image.open(query)\n",
    "    im.show()\n",
    "    for i in sorted(temp):\n",
    "        if query[-8:-4] in i[1][0][-13:-8]:\n",
    "            print(\"#CANDIDATES: \", i)\n",
    "            im=Image.open(i[1][0])\n",
    "            im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd3038-263c-4da7-83a2-a6253de316b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualise_matches(d, q, index):\n",
    "    query = q[0][index][0]\n",
    "    distmat = d[index]\n",
    "    gallery = q[1]\n",
    "    \n",
    "    temp = zip(distmat, gallery)\n",
    "    print(\"#SUS \", query)\n",
    "    im=Image.open(query)\n",
    "    im.show()\n",
    "    for i in sorted(temp):\n",
    "        print(\"#CANDIDATES: \", i)\n",
    "        im=Image.open(i[1][0])\n",
    "        im.show()\n",
    "\n",
    "for i in range(2):\n",
    "    visualise_matches(distmat, queries_and_galley, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc8387-b418-496a-8be5-69a92ce8e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualise_sorts(d, q, index):\n",
    "    query = q[0][index][0]\n",
    "    distmat = d[index]\n",
    "    gallery = q[1]\n",
    "    \n",
    "    temp = zip(distmat, gallery)\n",
    "    print(\"#SUS \", query)\n",
    "    im=Image.open(query)\n",
    "    im.show()\n",
    "    count = 0\n",
    "    for i in sorted(temp):\n",
    "        if count <= 50:\n",
    "            print(\"#SORTS: \", i)\n",
    "            im=Image.open(i[1][0])\n",
    "            im.show()\n",
    "        \n",
    "        if query[-8:-4] in i[1][0][-13:-8]:\n",
    "            print(\"#CANDIDATES: \", i)\n",
    "            im=Image.open(i[1][0])\n",
    "            im.show()\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2a12a-45c8-4080-8299-7bc7e2b08acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualise_sorts(distmat, queries_and_galley, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9789df-18c9-4e21-b74a-4704f87b7c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output_matches(d, q, index):\n",
    "    query = q[0][index][0]\n",
    "    distmat = d[index]\n",
    "    gallery = q[1]\n",
    "    \n",
    "    temp = zip(distmat, gallery)\n",
    "    # print(query)\n",
    "    # im=Image.open(query)\n",
    "    # im.show()\n",
    "    \n",
    "    output = {}\n",
    "    for i in sorted(temp):\n",
    "        if query[-8:-4] in i[1][0][-13:-8]:\n",
    "            if i[0] < 455 and output == {}:\n",
    "                output[int(i[1][0][-8:-4])] = 1\n",
    "            else:\n",
    "                output[int(i[1][0][-8:-4])] = 0\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7cb10-f00a-47a0-8a26-2c3c266c7c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "path = \"/notebooks/deep-person-reid/reid-data/results (5).csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108df20-b7d2-43d7-bcaa-1a3154179b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1600):\n",
    "    output = output_matches(distmat, queries_and_galley, i)\n",
    "    for j in output.keys():\n",
    "        df.at[j,\"class\"] = output[int(j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb792c-bd1c-4faf-abf8-56b466d7b7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2c752-a5f5-45ef-9415-322e972f523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/notebooks/file_transfer/submission_27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5eeaaa-2e8f-4d63-a2b5-f82e7cdd82c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a425860-385e-4423-b01c-607d85c19c9f",
   "metadata": {},
   "source": [
    "# Robotics challenge function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e052ce-acdd-425a-946a-e1b4afcb6c72",
   "metadata": {},
   "source": [
    "def targets_from_image(self, scene_img, target_img) -> BoundingBox:\n",
    "        '''Process image with re-id pipeline and return the detected objects and their classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        img : Any\n",
    "            Input image.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        results  : List[DetectedObject]\n",
    "            List of DetectedObjects.\n",
    "        '''\n",
    "        \n",
    "        # dummy data\n",
    "        bbox = BoundingBox(100,100,300,50)\n",
    "        obj = DetectedObject(\"1\", \"1\", bbox)\n",
    "        # DetectedObject: ['id', 'cls', 'bbox'] \n",
    "        # e.g. cls=0 means match class 0, cls=1 means match class 1, cls=2 means match class2.\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9e8dc-1686-4b44-8a79-fac982fe2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from torchreid.utils import load_pretrained_weights\n",
    "\n",
    "def crop_image(image_path, results_csv, candidate_save_to):\n",
    "    df = pd.read_csv(results_csv)\n",
    "    \n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(image_path)\n",
    "    w = image.width\n",
    "    h = image.height\n",
    "    \n",
    "    # Ready to save, check directoreis\n",
    "    if os.path.exists(candidate_save_to):\n",
    "        shutil.rmtree(candidate_save_to)\n",
    "    os.mkdir(candidate_save_to)\n",
    "    \n",
    "    # crop candidates\n",
    "    for row in df.index:\n",
    "        \n",
    "        # obtain coordinates for one target\n",
    "        ymin = df['ymin'][row]\n",
    "        xmin = df['xmin'][row]\n",
    "        ymax = df['ymax'][row]\n",
    "        xmax = df['xmax'][row]\n",
    "    \n",
    "    \n",
    "        # Compute x, y, width, height from params\n",
    "        xmin = w * float(xmin)\n",
    "        ymin = h * float(ymin) \n",
    "        xmax = w * float(xmax)\n",
    "        ymax = h * float(ymax)\n",
    "\n",
    "        # Crop the image using the provided coordinates\n",
    "        cropped_image = image.crop((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_image.save(candidate_save_to + f\"/{row}.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb3abd-8c8d-4279-9942-4c8d189ed323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/notebooks/deep-person-reid/reid-data/testcsv.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6bac9-4583-4b26-a1e6-6706a2eef3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/notebooks/deep-person-reid/reid-data/image_0000.png\"\n",
    "results_csv = \"/notebooks/deep-person-reid/reid-data/testcsv.csv\"\n",
    "save_to = \"/notebooks/deep-person-reid/reid-data/test\"\n",
    "crop_image(image_path, results_csv, save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189714ee-4667-4e57-a0be-4631a980d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(save_to):\n",
    "    image = Image.open(save_to + f\"/{i}\")\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab1c8-b4a1-4491-9228-f8d1824affe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reid(scene_img, results_csv, candidate_save_to, engine): \n",
    "    df = pd.read_csv(results_csv)\n",
    "    \n",
    "    # process/crop images in the scene\n",
    "    crop_image(image_path, results_csv, candidate_save_to)\n",
    "    \n",
    "    # target image should be stored in target path alrd\n",
    "    \n",
    "    # call test function, obtain matrix\n",
    "    _,distmat, queries_and_galley = engine.run(\n",
    "        save_dir=\"\",\n",
    "        max_epoch=4,\n",
    "        eval_freq=1,\n",
    "        print_freq=50,\n",
    "        test_only=True\n",
    "    )\n",
    "    \n",
    "    # for i in range(1600):\n",
    "    #     output = output_matches(distmat, queries_and_galley, i)\n",
    "    #     for j in output.keys():\n",
    "    #         df.at[j,\"class\"] = output[int(j)]\n",
    "    return distmat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f35026-8091-4f90-8912-004cf368ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/notebooks/deep-person-reid/reid-data/image_0000.png\"\n",
    "results_csv = \"/notebooks/deep-person-reid/reid-data/testcsv.csv\"\n",
    "save_to = \"/notebooks/deep-person-reid/reid-data/test\"\n",
    "reid(image_path, results_csv, save_to, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32da6d-f102-4e53-b2a4-29faf95fa34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/notebooks/deep-person-reid/reid-data/image_0000.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a339604-723d-429a-9f67-abcb246b145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.utils import FeatureExtractor\n",
    "\n",
    "extractor = FeatureExtractor(\n",
    "    model_name='osnet_ibn_x1_0',\n",
    "    model_path='/notebooks/deep-person-reid/log/til_osnet_ibn_x1_0_with_pretrained/model/model.pth.tar-10-95.7-460',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf71948-bdae-42e8-8724-0d3d4fa088b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b188c47-1e85-4641-bba4-e6788c1ad2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a3268-2ea0-4845-84b7-1b3ca3aa19a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
